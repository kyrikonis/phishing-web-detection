{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e884c5f5-3539-4e9e-9eff-ec58e646c367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import tldextract\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import entropy\n",
    "import warnings\n",
    "import json\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e856306-11fc-497b-b799-224cc6302062",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PROC = Path(\"../data/processed\")\n",
    "DATA_FEAT = Path('../data/features')\n",
    "DATA_FEAT.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "138a825b-8112-484c-bc60-5101a6fe4de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(DATA_PROC / 'enhanced_urls.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b548e275-f72f-49fd-ba0e-7e24d4e86b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((641119, 11),\n",
       " Index(['url', 'type', 'label', 'url_length', 'domain', 'has_https',\n",
       "        'special_char_count', 'digit_count', 'tld', 'path_depth',\n",
       "        'subdomain_count'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccc8ef8-ed30-4583-9cae-50ee9d0ac882",
   "metadata": {},
   "source": [
    "# feature engineering functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "005ba098-5650-4756-8910-a37020da3d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_query_features(url):\n",
    "    \"\"\"query and parameter feature extraction\"\"\"\n",
    "    try:\n",
    "        parsed = urlparse(url)\n",
    "        query = parsed.query\n",
    "        fragment = parsed.fragment\n",
    "        \n",
    "        # query features\n",
    "        query_length = len(query) if query else 0\n",
    "        fragment_length = len(fragment) if fragment else 0\n",
    "        num_params = len(parse_qs(query)) if query else 0\n",
    "        \n",
    "        # parameter length\n",
    "        max_param_length = 0\n",
    "        if query:\n",
    "            params = parse_qs(query)\n",
    "            for key, values in params.items():\n",
    "                max_param_length = max(max_param_length, len(key))\n",
    "                for value in values:\n",
    "                    max_param_length = max(max_param_length, len(value))\n",
    "        \n",
    "        return {\n",
    "            'query_length': query_length,\n",
    "            'fragment_length': fragment_length,\n",
    "            'num_params': num_params,\n",
    "            'max_param_length': max_param_length\n",
    "        }\n",
    "    except:\n",
    "        return {\n",
    "            'query_length': 0,\n",
    "            'fragment_length': 0,\n",
    "            'num_params': 0,\n",
    "            'max_param_length': 0\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6195be66-17e8-40d8-ae2e-c8b51865796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_features = df['url'].apply(extract_query_features).apply(pd.Series)\n",
    "df = pd.concat([df, query_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "821da216-3113-40f6-a89a-25d274bddafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['query_length', 'fragment_length', 'num_params', 'max_param_length'], dtype='object'),\n",
       " (641119, 15))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_features.columns, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32afc910-d389-4383-9bef-d35e98b1691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(text):\n",
    "    \"\"\"calculate Shannon entropy\"\"\"\n",
    "    if not text or pd.isna(text):\n",
    "        return 0\n",
    "    freq = Counter(text)\n",
    "    length = len(text)\n",
    "    if length <= 1:\n",
    "        return 0\n",
    "    entropy_val = -sum((count/length) * math.log2(count/length) for count in freq.values())\n",
    "    return entropy_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4119d295-6b3e-44f4-ae53-10fb2d4d3428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lexical_features(url):\n",
    "    \"\"\"extract lexical and character-based features\"\"\"\n",
    "    if not url or pd.isna(url):\n",
    "        return {\n",
    "            'entropy': 0,\n",
    "            'vowel_consonant_ratio': 0,\n",
    "            'char_repeat_ratio': 0,\n",
    "            'uppercase_ratio': 0,\n",
    "            'special_char_ratio': 0,\n",
    "            'digit_ratio': 0\n",
    "        }\n",
    "    \n",
    "    url_len = len(url)\n",
    "    \n",
    "    # Entropy\n",
    "    entropy = calculate_entropy(url)\n",
    "    \n",
    "    # Character ratios\n",
    "    vowels = len(re.findall(r'[aeiouAEIOU]', url))\n",
    "    consonants = len(re.findall(r'[bcdfghjklmnpqrstvwxyzBCDFGHJKLMNPQRSTVWXYZ]', url))\n",
    "    vowel_consonant_ratio = vowels / (consonants + 1)\n",
    "    \n",
    "    # Character repetition\n",
    "    char_counts = Counter(url.lower())\n",
    "    repeated_chars = sum(1 for count in char_counts.values() if count > 1)\n",
    "    char_repeat_ratio = repeated_chars / url_len\n",
    "    \n",
    "    # Case analysis\n",
    "    uppercase_count = sum(1 for c in url if c.isupper())\n",
    "    uppercase_ratio = uppercase_count / url_len\n",
    "    \n",
    "    # Calculate special char and digit ratios directly (avoid DataFrame lookup!)\n",
    "    special_chars = len(re.findall(r'[^a-zA-Z0-9]', url))\n",
    "    digits = len(re.findall(r'\\d', url))\n",
    "    \n",
    "    special_char_ratio = special_chars / url_len if url_len > 0 else 0\n",
    "    digit_ratio = digits / url_len if url_len > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'entropy': entropy,\n",
    "        'vowel_consonant_ratio': vowel_consonant_ratio,\n",
    "        'char_repeat_ratio': char_repeat_ratio,\n",
    "        'uppercase_ratio': uppercase_ratio,\n",
    "        'special_char_ratio': special_char_ratio,\n",
    "        'digit_ratio': digit_ratio\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc578b14-7ee5-4d0a-94c5-1ce317e08d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_features = df['url'].apply(extract_lexical_features_optimized).apply(pd.Series)\n",
    "df = pd.concat([df, lexical_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15d74079-7d21-4656-a6f9-9114e753af45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['entropy', 'vowel_consonant_ratio', 'char_repeat_ratio',\n",
       "        'uppercase_ratio', 'special_char_ratio', 'digit_ratio'],\n",
       "       dtype='object'),\n",
       " (641119, 21))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_features.columns, df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc61448-2573-4b0d-bd04-379bdd288783",
   "metadata": {},
   "source": [
    "# word based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e746c8c-5d51-45aa-9892-1a80848d1432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_word_features(url):\n",
    "    if not url or pd.isna(url):\n",
    "        return {\n",
    "            'word_count': 0,\n",
    "            'avg_word_length': 0,\n",
    "            'longest_word_length': 0\n",
    "        }\n",
    "    \n",
    "    # Extract alphabetic words\n",
    "    words = re.findall(r'[a-zA-Z]+', url)\n",
    "    \n",
    "    if not words:\n",
    "        return {\n",
    "            'word_count': 0,\n",
    "            'avg_word_length': 0,\n",
    "            'longest_word_length': 0\n",
    "        }\n",
    "    \n",
    "    word_count = len(words)\n",
    "    avg_word_length = sum(len(word) for word in words) / word_count\n",
    "    longest_word_length = max(len(word) for word in words)\n",
    "    \n",
    "    return {\n",
    "        'word_count': word_count,\n",
    "        'avg_word_length': avg_word_length,\n",
    "        'longest_word_length': longest_word_length\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bebebb57-3d71-4122-9b22-817488137915",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = df['url'].apply(extract_word_features).apply(pd.Series)\n",
    "df = pd.concat([df, word_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9e1c142-30d7-4e0c-aa1a-52128f34d385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['word_count', 'avg_word_length', 'longest_word_length'], dtype='object'),\n",
       " (641119, 24))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_features.columns, df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160f1bea-04de-4928-885e-11984d52915b",
   "metadata": {},
   "source": [
    "# Security issues indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b52f3b8-7f2e-478e-85a6-365559c787c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUSPICIOUS_TLDS = ['tk', 'ml', 'ga', 'cf', 'top', 'work', 'click', 'download', 'zip']\n",
    "URL_SHORTENERS = ['bit.ly', 'tinyurl.com', 't.co', 'goo.gl', 'short.link', 'ow.ly']\n",
    "SUSPICIOUS_KEYWORDS = ['secure', 'account', 'update', 'confirm', 'verify', 'suspend', \n",
    "                      'restricted', 'urgent', 'expire', 'activate', 'validate', 'alert']\n",
    "BRAND_KEYWORDS = ['paypal', 'amazon', 'google', 'microsoft', 'apple', 'facebook', \n",
    "                 'bank', 'visa', 'mastercard', 'netflix', 'spotify']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "924d2f6d-90a5-4db6-afe6-931dff1cd340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_security_features(url, tld):\n",
    "    if not url or pd.isna(url):\n",
    "        return {\n",
    "            'has_ip': 0,\n",
    "            'suspicious_tld': 0,\n",
    "            'is_url_shortener': 0,\n",
    "            'has_suspicious_words': 0,\n",
    "            'has_brand_keywords': 0,\n",
    "            'social_engineering_score': 0\n",
    "        }\n",
    "    \n",
    "    url_lower = url.lower()\n",
    "    \n",
    "    # IP address detection\n",
    "    ip_pattern = r'\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b'\n",
    "    has_ip = int(bool(re.search(ip_pattern, url)))\n",
    "    \n",
    "    # detect suspicious tld \n",
    "    suspicious_tld = int(tld.lower() in SUSPICIOUS_TLDS) if pd.notna(tld) else 0\n",
    "    \n",
    "    # url shortener\n",
    "    is_url_shortener = int(any(shortener in url_lower for shortener in URL_SHORTENERS))\n",
    "    \n",
    "    # suspicious keywords\n",
    "    has_suspicious_words = int(any(word in url_lower for word in SUSPICIOUS_KEYWORDS))\n",
    "    \n",
    "    # company keywords, could be case of impersonation\n",
    "    has_brand_keywords = int(any(brand in url_lower for brand in BRAND_KEYWORDS))\n",
    "    \n",
    "    # social engineering 'score' (count of suspicious terms)\n",
    "    se_words = ['urgent', 'expire', 'suspend', 'verify', 'confirm', 'secure', 'alert', 'warning']\n",
    "    social_engineering_score = sum(1 for word in se_words if word in url_lower)\n",
    "    \n",
    "    return {\n",
    "        'has_ip': has_ip,\n",
    "        'suspicious_tld': suspicious_tld,\n",
    "        'is_url_shortener': is_url_shortener,\n",
    "        'has_suspicious_words': has_suspicious_words,\n",
    "        'has_brand_keywords': has_brand_keywords,\n",
    "        'social_engineering_score': social_engineering_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "174499e7-c53e-4685-a968-98e6899c8b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "security_features = df.apply(lambda row: extract_security_features(row['url'], row['tld']), axis=1).apply(pd.Series)\n",
    "df = pd.concat([df, security_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b574253f-7e1a-43eb-825f-390e151f08e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['has_ip', 'suspicious_tld', 'is_url_shortener', 'has_suspicious_words',\n",
       "        'has_brand_keywords', 'social_engineering_score'],\n",
       "       dtype='object'),\n",
       " (641119, 30))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "security_features.columns, df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e0e1b9-970f-46e3-9447-352ede6fae74",
   "metadata": {},
   "source": [
    "# Obfuscation detection features\n",
    "Inspo: https://cloud.google.com/blog/topics/threat-intelligence/url-obfuscation-schema-abuse/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9501288a-8c64-4315-8e93-046001c7b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_obfuscation_features(url):\n",
    "    if not url or pd.isna(url):\n",
    "        return {\n",
    "            'hex_chars': 0,\n",
    "            'percent_encoding': 0,\n",
    "            'consecutive_dots': 0,\n",
    "            'consecutive_hyphens': 0,\n",
    "            'homograph_chars': 0\n",
    "        }\n",
    "    \n",
    "    # hex encoding\n",
    "    hex_pattern = r'%[0-9a-fA-F]{2}'\n",
    "    hex_chars = len(re.findall(hex_pattern, url))\n",
    "    \n",
    "    # % encoding count\n",
    "    percent_encoding = url.count('%')\n",
    "    \n",
    "    #consecutive specialcharacters\n",
    "    consecutive_dots = len(re.findall(r'\\.{2,}', url))\n",
    "    consecutive_hyphens = len(re.findall(r'-{2,}', url))\n",
    "\n",
    "    homographs = ['а', 'е', 'о', 'р', 'с', 'х', 'у'] \n",
    "    homograph_chars = sum(1 for char in url if char in homographs)\n",
    "    \n",
    "    return {\n",
    "        'hex_chars': hex_chars,\n",
    "        'percent_encoding': percent_encoding,\n",
    "        'consecutive_dots': consecutive_dots,\n",
    "        'consecutive_hyphens': consecutive_hyphens,\n",
    "        'homograph_chars': homograph_chars\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8e7bcb18-a9d0-4ba1-981e-a9731f52079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "obfuscation_features = df['url'].apply(extract_obfuscation_features).apply(pd.Series)\n",
    "df = pd.concat([df, obfuscation_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f28ad313-85ad-43b9-bd56-9ed5ce9922e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['hex_chars', 'percent_encoding', 'consecutive_dots',\n",
       "        'consecutive_hyphens', 'homograph_chars'],\n",
       "       dtype='object'),\n",
       " (641119, 35))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obfuscation_features.columns, df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6872d171-cb98-45d0-a814-ea5f7381407a",
   "metadata": {},
   "source": [
    "# Domain and Network Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b270836f-8701-46cf-84bf-7ddd6faf7488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_network_features(url, domain):\n",
    "    if not url or pd.isna(url):\n",
    "        return {\n",
    "            'domain_entropy': 0,\n",
    "            'domain_tokens': 0,\n",
    "            'subdomain_length': 0,\n",
    "            'has_port': 0,\n",
    "            'port_number': 80,\n",
    "            'is_https': 0\n",
    "        }\n",
    "    \n",
    "    # entropy for domain\n",
    "    domain_entropy = calculate_entropy(domain) if pd.notna(domain) else 0\n",
    "    \n",
    "    #domain tokens (split by dots and hyphens)\n",
    "    domain_tokens = 0\n",
    "    if pd.notna(domain):\n",
    "        domain_tokens = len([token for token in re.split(r'[.-]', domain) if token])\n",
    "    \n",
    "    subdomain_length = 0\n",
    "    try:\n",
    "        extracted = tldextract.extract(url)\n",
    "        subdomain_length = len(extracted.subdomain) if extracted.subdomain else 0\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #port analsis\n",
    "    has_port = 0\n",
    "    port_number = 80\n",
    "    try:\n",
    "        parsed = urlparse(url)\n",
    "        if parsed.port:\n",
    "            has_port = 1\n",
    "            port_number = parsed.port\n",
    "        elif parsed.scheme == 'https':\n",
    "            port_number = 443\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # https detection again\n",
    "    is_https = int(url.lower().startswith('https://'))\n",
    "    \n",
    "    return {\n",
    "        'domain_entropy': domain_entropy,\n",
    "        'domain_tokens': domain_tokens,\n",
    "        'subdomain_length': subdomain_length,\n",
    "        'has_port': has_port,\n",
    "        'port_number': port_number,\n",
    "        'is_https': is_https\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "22a0ad14-415e-41bd-9405-6677d9bb91c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_features = df.apply(lambda row: extract_network_features(row['url'], row['domain']), axis=1).apply(pd.Series)\n",
    "df = pd.concat([df, network_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1e3523cc-a68a-4179-9a75-510283326797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['domain_entropy', 'domain_tokens', 'subdomain_length', 'has_port',\n",
       "        'port_number', 'is_https'],\n",
       "       dtype='object'),\n",
       " (641119, 41))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_features.columns, df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4baeaf9-9e15-4ef1-8d1d-9f01bdafe1de",
   "metadata": {},
   "source": [
    "# pattern detection features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6e3b3245-e1a1-4eb8-b21e-fb0559df90cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pattern_features(url):\n",
    "    \"\"\"Extract advanced pattern detection features\"\"\"\n",
    "    if not url or pd.isna(url):\n",
    "        return {\n",
    "            'contains_date_pattern': 0,\n",
    "            'contains_version_pattern': 0,\n",
    "            'redirect_indicators': 0,\n",
    "            'file_extension_count': 0\n",
    "        }\n",
    "    \n",
    "    url_lower = url.lower()\n",
    "    \n",
    "    # Date patterns (might indicate time-sensitive attacks)\n",
    "    date_patterns = [r'\\d{4}', r'\\d{2}-\\d{2}', r'\\d{2}_\\d{2}', r'20\\d{2}']\n",
    "    contains_date_pattern = int(any(re.search(pattern, url) for pattern in date_patterns))\n",
    "    \n",
    "    # Version patterns\n",
    "    version_pattern = r'v?\\d+\\.\\d+'\n",
    "    contains_version_pattern = int(bool(re.search(version_pattern, url)))\n",
    "    \n",
    "    # Redirect indicators\n",
    "    redirect_words = ['redirect', 'goto', 'link', 'click', 'ref', 'track', 'forward']\n",
    "    redirect_indicators = sum(1 for word in redirect_words if word in url_lower)\n",
    "    \n",
    "    # File extensions\n",
    "    file_extensions = re.findall(r'\\.[a-zA-Z0-9]{1,4}(?:/|$|\\?)', url)\n",
    "    file_extension_count = len(set(file_extensions))\n",
    "    \n",
    "    return {\n",
    "        'contains_date_pattern': contains_date_pattern,\n",
    "        'contains_version_pattern': contains_version_pattern,\n",
    "        'redirect_indicators': redirect_indicators,\n",
    "        'file_extension_count': file_extension_count\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "21566afa-01d9-4ce0-ace0-76cdc38b9a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_features = df['url'].apply(extract_pattern_features).apply(pd.Series)\n",
    "df = pd.concat([df, pattern_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6dd4e13a-22ce-4113-b9fe-829c3ffa35b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['contains_date_pattern', 'contains_version_pattern',\n",
       "        'redirect_indicators', 'file_extension_count'],\n",
       "       dtype='object'),\n",
       " (641119, 50))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_features.columns, df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96c85d6-c91f-4cac-b962-f4a0589be46d",
   "metadata": {},
   "source": [
    "# Feature summary / quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4ff58cb7-55c7-48fe-8269-0654252960c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_feature_quality(df):\n",
    "    \n",
    "    numerical_features = df.select_dtypes(include=[np.number])\n",
    "    feature_cols = [col for col in numerical_features.columns if col not in ['label']]\n",
    "    \n",
    "    print(f\"Total features created: {len(feature_cols)}\")\n",
    "    print(f\"Original dataset columns: url, label, type\")\n",
    "    print(f\"New engineered features: {len(feature_cols) - 2}\")  # -2 for original label and any index\n",
    "    \n",
    "    feature_categories = {\n",
    "        'URL Structure': ['url_length', 'domain_length', 'path_depth', 'subdomain_count', \n",
    "                         'query_length', 'fragment_length', 'num_params'],\n",
    "        'Character Analysis': ['special_char_count', 'digit_count', 'entropy', 'vowel_consonant_ratio',\n",
    "                              'char_repeat_ratio', 'special_char_ratio', 'digit_ratio', 'uppercase_ratio'],\n",
    "        'Word Analysis': ['word_count', 'avg_word_length', 'longest_word_length'],\n",
    "        'Security Indicators': ['has_ip', 'suspicious_tld', 'is_url_shortener', 'has_suspicious_words',\n",
    "                               'has_brand_keywords', 'social_engineering_score'],\n",
    "        'Obfuscation': ['hex_chars', 'percent_encoding', 'consecutive_dots', 'consecutive_hyphens'],\n",
    "        'Network Features': ['domain_entropy', 'domain_tokens', 'has_port', 'is_https'],\n",
    "        'Ratios': ['domain_url_ratio', 'path_url_ratio', 'query_url_ratio', 'param_url_ratio'],\n",
    "        'Patterns': ['contains_date_pattern', 'contains_version_pattern', 'redirect_indicators']\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nFeature Categories:\")\n",
    "    total_categorized = 0\n",
    "    for category, features in feature_categories.items():\n",
    "        existing_features = [f for f in features if f in df.columns]\n",
    "        total_categorized += len(existing_features)\n",
    "        print(f\"  {category:20s}: {len(existing_features):2d} features\")\n",
    "    \n",
    "    # missing values checking\n",
    "    missing_features = numerical_features.isnull().sum()\n",
    "    features_with_missing = missing_features[missing_features > 0]\n",
    "    \n",
    "    if len(features_with_missing) > 0:\n",
    "        print(f\"\\nFeatures with missing values:\")\n",
    "        for feature, count in features_with_missing.items():\n",
    "            print(f\"  {feature}: {count} ({count/len(df)*100:.2f}%)\")\n",
    "    else:\n",
    "        print(f\"\\n✓ No missing values in engineered features\")\n",
    "    \n",
    "    print(f\"\\nFeature Value Ranges:\")\n",
    "    for category, features in list(feature_categories.items())[:3]:  # Show first 3 categories\n",
    "        existing_features = [f for f in features if f in df.columns][:3]  # Show max 3 per category\n",
    "        if existing_features:\n",
    "            print(f\"  {category}:\")\n",
    "            for feature in existing_features:\n",
    "                min_val = df[feature].min()\n",
    "                max_val = df[feature].max()\n",
    "                mean_val = df[feature].mean()\n",
    "                print(f\"    {feature:20s}: [{min_val:8.3f}, {max_val:8.3f}] (μ={mean_val:6.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "66838842-b4c1-43d1-b6bf-c873c7cdf137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features created: 40\n",
      "Original dataset columns: url, label, type\n",
      "New engineered features: 38\n",
      "\n",
      "Feature Categories:\n",
      "  URL Structure       :  6 features\n",
      "  Character Analysis  :  8 features\n",
      "  Word Analysis       :  3 features\n",
      "  Security Indicators :  6 features\n",
      "  Obfuscation         :  4 features\n",
      "  Network Features    :  4 features\n",
      "  Ratios              :  0 features\n",
      "  Patterns            :  3 features\n",
      "\n",
      "✓ No missing values in engineered features\n",
      "\n",
      "Feature Value Ranges:\n",
      "  URL Structure:\n",
      "    url_length          : [   1.000, 2175.000] (μ=59.762)\n",
      "    path_depth          : [   0.000,   39.000] (μ= 0.644)\n",
      "    subdomain_count     : [   0.000,   33.000] (μ= 0.601)\n",
      "  Character Analysis:\n",
      "    special_char_count  : [   0.000,  372.000] (μ= 9.229)\n",
      "    digit_count         : [   0.000, 1204.000] (μ= 5.372)\n",
      "    entropy             : [   0.000,    7.504] (μ= 4.218)\n",
      "  Word Analysis:\n",
      "    word_count          : [   0.000,  309.000] (μ= 9.111)\n",
      "    avg_word_length     : [   0.000,   61.171] (μ= 5.427)\n",
      "    longest_word_length : [   0.000,  254.000] (μ=10.930)\n"
     ]
    }
   ],
   "source": [
    "analyse_feature_quality(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5f01a3-27a1-42ec-9d1c-3cb047d13abe",
   "metadata": {},
   "source": [
    "# Feature correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8c1bc873-c5b8-4dcd-9be6-8ea39c128a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_feature_correlations(df):\n",
    "    numerical_features = df.select_dtypes(include=[np.number])\n",
    "    feature_cols = [col for col in numerical_features.columns if col not in ['label']]\n",
    "    \n",
    "    # correlation with target\n",
    "    correlations = numerical_features[feature_cols].corrwith(numerical_features['label'])\n",
    "    correlations = correlations.abs().sort_values(ascending=False)\n",
    "    \n",
    "    print(f\"\\nTop 15 Most Predictive Features:\")\n",
    "    print(\"-\" * 50)\n",
    "    for i, (feature, corr) in enumerate(correlations.head(15).items(), 1):\n",
    "        print(f\"{i:2d}. {feature:25s}: {corr:.4f}\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Top 15 feature correlations\n",
    "    top_correlations = correlations.head(15)\n",
    "    \n",
    "    bars = plt.bar(range(len(top_correlations)), top_correlations.values, \n",
    "                   color=plt.cm.viridis(np.linspace(0, 1, len(top_correlations))))\n",
    "    \n",
    "    plt.title('Top 15 Feature Correlations with Target', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Absolute Correlation with Target')\n",
    "    plt.xticks(range(len(top_correlations)), top_correlations.index, rotation=45, ha='right')\n",
    "    \n",
    "    for i, (bar, corr) in enumerate(zip(bars, top_correlations.values)):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.005,\n",
    "                f'{corr:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc914af-2eed-44fd-a01e-f3bf9b20f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = analyse_feature_correlations(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "27b70f73-24c5-43b8-919a-f383a8224966",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, ~df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bb3c86b0-e7e0-47d4-a9bf-481efcbf2a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(DATA_FEAT / 'url_features_complete.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7969e26e-1f2f-4c5e-b24d-d88a876813d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_info = {\n",
    "    'total_features': df.shape[1],\n",
    "    'total_rows': df.shape[0],\n",
    "    'numerical_features': len(df.select_dtypes(include=[np.number]).columns),\n",
    "    'categorical_features': len(df.select_dtypes(include=['object']).columns),\n",
    "    'top_15_features': correlations.head(15).index.tolist(),\n",
    "    'feature_correlations': correlations.to_dict()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0b185094-d7d1-4a39-b43b-67ce7beac86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_FEAT / 'feature_metadata.json', 'w') as f:\n",
    "    json.dump(feature_info, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78aed80-337f-403b-872e-25a2bd76c4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1b7d6c-2b01-41af-b961-5b5860b8b56a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (phishing-ds)",
   "language": "python",
   "name": "phishing-ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
